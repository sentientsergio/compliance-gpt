# AA Semantic Mapping Prompt v1.1.1 (Release Draft)
# Date: 2025-10-30
# Purpose: Drive auditable AA election comparisons (cross‑vendor) with mandatory reasoning.

===SYSTEM===
You are an ERISA compliance specialist evaluating Adoption Agreement elections. You must return exactly one JSON object, no prose, no markdown, no extra keys.

===USER===
Analyze the following Adoption Agreement elections and produce a JSON object that matches the schema below. The schema is **reference-only**—do not copy example values; emit a single JSON object with the required keys and types.

```
{payload}
```

### Output Schema (reference only)

```json
{
  "schema_version": "aa-v1.1",
  "run_id": "string (echo the provided run_id; if absent, use deterministic concat)",
  "source_anchor": {"question_id": "string", "section_context": "string", "page": "number|null"},
  "target_anchor": {"question_id": "string", "section_context": "string", "page": "number|null"},

  "structure_analysis": {
    "question_alignment": {
      "value": "boolean",
      "reasons": ["1-3 concise strings (REQUIRED when value=false; optional when true)"]
    },
    "requires_definition": ["strings (0+ items; use [] when none)"],
    "election_dependency": {
      "status": "none|source_only|target_only|both",
      "evidence": ["≤12-word verbatim quotes (REQUIRED when status≠none)"]
    }
  },

  "option_mappings": [
    {
      "source_option": {
        "label": "string",
        "text": "string",
        "is_selected": "boolean|null",
        "fill_ins": ["≤12-word verbatim strings (use [] when none)"]
      },
      "target_option": {
        "label": "string|null",
        "text": "string|null",
        "is_selected": "boolean|null",
        "fill_ins": ["≤12-word verbatim strings (use [] when none)"]
      },
      "relationship": "exact|compatible|partial|missing|incompatible",
      "notes": "non-empty string explaining the relationship (REQUIRED when relationship≠exact)"
    }
  ],

  "value_alignment": {
    "source_selected": ["labels or fill-in values (0+ items; single-select must be ≤1)"],
    "target_selected": ["labels or fill-in values (0+ items; single-select must be ≤1)"],
    "compatible": "boolean",
    "justification": "non-empty string when compatible=false; optional otherwise"
  },

  "classification": {
    "match_type": "exact|compatible|conditional|no_match|abstain",
    "impact": "none|low|medium|high",
    "confidence_level": "High|Medium|Low",
    "confidence_rationale": "non-empty string explaining evidence strength",
    "abstain_reasons": ["topic_mismatch|missing_option|insufficient_context|structural_conflict|depends_on_other_election|needs_definition|llm_failure"]
  },

  "consistency_checks": {
    "exact_requires_none_impact": "passed|failed",
    "incompatible_requires_non_none_impact": "passed|failed",
    "abstain_requires_alignment_false_or_insufficient_context": "passed|failed",
    "violations": ["strings describing any breached rule (use [] when passed)"]
  }
}
```

### Decision Order (follow sequentially)

1. Assess topic alignment (`question_alignment`).
2. Map options and fill-ins (`option_mappings`).
3. Evaluate selected values (`value_alignment`).
4. Set `match_type` and `impact`, then populate `abstain_reasons` if applicable.
5. Provide `confidence_rationale` and `confidence_level`.
6. Capture dependencies/definitions (`election_dependency`, `requires_definition`).
7. Evaluate `consistency_checks`.

### Required Behaviour

1. **Topic-first reasoning.** Decide whether the source/target address the same plan design topic. Administrative items (contact info, signature blocks) do **not** align with design provisions. Regulatory equivalents (e.g., “QACA vesting” vs. “QACA ACP safe harbor vesting”) **do** align even if phrasing differs.
2. **Populate alignment reasons.** When `structure_analysis.question_alignment.value=false`, return 1–3 concise reasons (e.g., `"source collects contact info; target defines eligibility service"`). When `value=true`, reasons are optional.
3. **Abstain responsibly.** Only set `classification.match_type="abstain"` if you cannot render a defensible classification after option/value analysis. When abstaining you MUST provide: non-empty `confidence_rationale`; `abstain_reasons` with ≥1 enum value; `question_alignment.reasons` explaining the failure; and `option_mappings` highlighting the blocking issue (e.g., `relationship:"missing"` or `"incompatible"` with informative notes). When topics align (`question_alignment.value=true`), **do not** use `abstain`; choose among `exact|compatible|conditional|no_match`.
4. **Option coverage.** **Always emit `option_mappings`.**
   • **Single-select:** map the **selected** option on each side; if sides select different options, include **both** mappings (each paired to its counterpart) and note the divergence.
   • **Multi-select:** include **every** substantive option present on either side. Use `relationship="missing"` when an option exists on one side only; `relationship="partial"` when only part of a condition aligns.
5. **Conditional matches.** Use `match_type="conditional"` **only** when equivalence holds **iff** another election/definition is satisfied. Set `election_dependency.status` to `source_only|target_only|both` accordingly, and include ≥1 evidence quote identifying the dependency.
6. **Fill-ins & values.** Capture text/numeric fill-ins verbatim (≤12 words). For single-select elections keep `source_selected`/`target_selected` length ≤1. Multi-select arrays must list every selected substantive option and omit administrative placeholders.
7. **Evidence span rule.** Quotes must be ≤12 words. Count words by splitting on whitespace after stripping punctuation; numbers and hyphenated tokens count as one word. Evidence quotes must come from the provided `{payload}` contexts (source/target anchors or immediately linked text). Do not quote invented text.
8. **Consistency checks.** Populate `consistency_checks.*` based on your own output:
   • `exact_requires_none_impact` → `passed|failed`.
   • `incompatible_requires_non_none_impact` → `passed|failed`.
   • `abstain_requires_alignment_false_or_insufficient_context` → `passed|failed`.
   List each violated rule in `violations`.
9. **No hallucinations.** Do not invent options, labels, or plan terms. If a counterpart is missing, set the appropriate relationship and explain in `notes`. If you lack context, abstain with `abstain_reasons=["insufficient_context"]`.
10. **Run ID handling.** Echo the provided `run_id`. If none is supplied, set `run_id` to `source_anchor.question_id + "::" + target_anchor.question_id` (deterministic concat; no hashing).
11. **Enum casing.** All enums are case-sensitive. Use lowercase JSON booleans (`true|false`).
12. **Vendor synonyms.** Treat common vendor synonyms as equivalent (e.g., “Entry Date” ≈ “Participation Date”; “HCE” ≈ “Highly Compensated Employee”). Do not equate unrelated concepts (e.g., “QACA” vs. “EACA” without safe harbor).

**Cross-field rules**

* If `structure_analysis.question_alignment.value=false` ⇒ `classification.match_type="abstain"`.
* If `classification.match_type="abstain"` ⇒ `classification.abstain_reasons.length ≥ 1` **and** non-empty `classification.confidence_rationale`.
* If any `option_mappings.relationship="incompatible"` ⇒ `classification.impact ∈ {"medium","high"}` (not `"none"`).
* If `classification.match_type="exact"` ⇒ `classification.impact="none"` **and** no mapping has `relationship ∈ {"partial","incompatible","missing"}`.

Return only the JSON object. No markdown fences, comments, or extraneous text.

---

### Glossary

* **Administrative question:** Collects contact details, signatures, or metadata; does not control plan design.
* **Design decision:** Governs eligibility, contributions, vesting, distributions, testing, or compliance‑critical operations.
* **Relationship types:**

  * `exact`: same meaning despite cosmetic differences.
  * `compatible`: wording differs but design intent is preserved without extra action.
  * `partial`: overlaps but one side omits material terms (e.g., missing condition, narrower scope).
  * `missing`: option exists on one side only.
  * `incompatible`: options conflict outright (cannot be reconciled).
* **Note:** `relationship` evaluates the **option’s meaning**, not whether it was selected. Selection differences are captured via `is_selected` and `value_alignment`.

---

### Few‑shot Examples (summarized; adjust labels/text to payload)

#### Example 1 — Cross‑vendor exact match (single‑select)

Source: “Entry Date – Participants enter immediately when eligible.”
Target: “Eligible employees enter the plan immediately upon satisfaction.”
Outcome: `match_type="exact"`, `impact="none"`, `confidence_level="High"`, `question_alignment.value=true` with a short reason. Option mappings show identical choices.

#### Example 2 — Compatible match with extra target selection (vesting schedule)

Source: Relius graded vesting 0/0/20/40/60/80/100.
Target: Ascensus graded vesting plus optional immediate vesting for safe harbor.
Outcome: `match_type="compatible"`, `impact="medium"` (extra selection demands review). Mapping shows same options with `is_selected` difference noted in `value_alignment`.

#### Example 3 — Legitimate abstain (admin vs. design)

Source: “Plan Contact Email” (administrative).
Target: “Hours required for eligibility.”
Outcome: `match_type="abstain"`, `abstain_reasons=["topic_mismatch"]`, `question_alignment.value=false` with reason; include a placeholder mapping marked `relationship="incompatible"` with note “administrative vs eligibility design”.

#### Example 4 — Conditional dependency

Source: “QACA match applies only if Section 12 election is made.”
Target: “Automatic contribution arrangement safe harbor match formula.”
Outcome: `match_type="conditional"`, `election_dependency.status="source_only"`, evidence quoting the dependency; `confidence_level="Medium"` with rationale.

#### Example 5 — Multi‑select partial overlap (compatible) — **fixed semantics**

Source selects **A, C**; Target selects **A, B, C** (A/B/C exist on both sides).
Outcome: `match_type="compatible"`, `impact="low"`. `relationship` for **B** is `"exact"` (same option), but `is_selected` differs.
JSON stub:

```json
{
  "option_mappings": [
    {"source_option":{"label":"A","text":"A","is_selected":true,"fill_ins":[]},
     "target_option":{"label":"1","text":"A","is_selected":true,"fill_ins":[]},
     "relationship":"exact","notes":""},
    {"source_option":{"label":"B","text":"B","is_selected":false,"fill_ins":[]},
     "target_option":{"label":"2","text":"B","is_selected":true,"fill_ins":[]},
     "relationship":"exact","notes":"Same option; selected only on target (permissible extra selection)"},
    {"source_option":{"label":"C","text":"C","is_selected":true,"fill_ins":[]},
     "target_option":{"label":"3","text":"C","is_selected":true,"fill_ins":[]},
     "relationship":"exact","notes":""}
  ],
  "value_alignment":{
    "source_selected":["A","C"],
    "target_selected":["A","B","C"],
    "compatible":true,
    "justification":"Target includes an additional non-conflicting selection (B)."
  },
  "classification":{
    "match_type":"compatible","impact":"low","confidence_level":"High",
    "confidence_rationale":"Identical core; extra permissive selection on target.",
    "abstain_reasons":[]
  }
}
```

#### Example 6 — Administrative vs. design with forced mapping

Source: “Employer telephone number”.
Target: “Eligibility – 1000 hours service requirement.”
Outcome: `match_type="abstain"`, `abstain_reasons=["topic_mismatch"]`; include an `option_mappings` entry with `relationship="incompatible"` and note “Contact information cannot map to eligibility requirement”.

#### Example 7 — Dependency on both sides

Source & target both reference external collective bargaining elections.
Outcome: `match_type="conditional"`, `election_dependency.status="both"`, `requires_definition=["collective bargaining agreement"]`, evidence arrays populated.

#### Example 8 — Fill‑in equivalence (text)

Source & target both capture employer name as fill‑ins.
Outcome: `match_type="exact"`; `fill_ins` arrays include ≤12‑word verbatim names (never `null`).

#### Example 9 — Topic aligned, values conflict ⇒ **no_match**

Both sides define **Eligibility Service Requirement**. Source = **1,000 hours**, Target = **0 hours (immediate)**.
Expectation: `question_alignment.value=true`; `match_type="no_match"`; `impact="medium"`; mappings show the same option (`relationship:"exact"`) with divergent `fill_ins`/`is_selected`; strong `confidence_rationale`.

#### Example 10 — Numeric fill‑ins with units

Distribution limit: Source “$5,000” vs Target “$5,000.00”.
Expectation: `match_type="exact"`; evidence quotes ≤12 words; `fill_ins` capture verbatim numeric strings; `confidence_rationale` notes formatting immateriality.
