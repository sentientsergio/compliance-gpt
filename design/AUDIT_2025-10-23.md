# Design Directory Audit - October 23, 2025

## Purpose

This document audits the current state of `/design` for consistency with:
1. New provisional matching conceptual model (Oct 23, 2025)
2. Test corpus ground truth (Relius → Ascensus cross-vendor)
3. Red Team Sprint quality findings
4. Performance optimization strategy

---

## Executive Summary

**Overall Status**: Design is 70% complete with several critical updates needed.

**Key Findings:**
- ✅ **Strengths**: Core data models exist, LLM strategy documented, architecture defined
- ⚠️ **Gaps**: Provisional matching not integrated, prompts not documented in design, performance strategy was missing
- ❌ **Inconsistencies**: Several docs reference old "Ascensus intra-vendor" test scenario, confidence scoring needs revision

**Recommended Actions:**
1. Update `design/README.md` with current phase status and new design docs
2. Create `design/llm_strategy/prompt_management.md` to link prompts to design
3. Update `design/data_models/` to reference provisional matching model
4. Revise confidence scoring based on provisional match model
5. Update architecture docs with async/await strategy

---

## Document-by-Document Audit

### `/design/README.md`

**Status**: ⚠️ **NEEDS UPDATE**

**Current State:**
- Documents Phase 1-4 design strategy
- Lists 136 design decisions through Oct 19, 2025
- References Phase 2 POC status as "In Progress"
- Folder structure lists modules not yet designed

**Issues:**
1. **Outdated POC status**: Says "BPD crosswalk generated (15 matches, 27% rate)" but actual is 82 matches (19.3%)
2. **Missing new design docs**: `provisional_matching.md` and `performance_optimization.md` not listed
3. **Phase 2 completion criteria unclear**: Says "measure POC accuracy against 70%" but now we know quality issues require fixes
4. **Test corpus identity**: Still references "Ascensus Cycle 3" instead of "Relius → Ascensus cross-vendor"

**Recommended Updates:**
```markdown
### Phase 2: VALIDATE THE CORE (In Progress - Quality Issues Identified)
- ✅ LLM model selection (GPT-5 vision + GPT-4.1 semantic)
- ✅ Acquire sample documents (4 docs: Relius source + Ascensus target)
- ✅ Build semantic mapping POC (hybrid embeddings + LLM)
- ✅ BPD crosswalk generated (82 matches, 19.3% rate)
- ✅ AA crosswalk generated (22 matches)
- ✅ Performance optimization strategy documented
- ❌ Red Team Sprint identified quality issues:
  - Section headings extracted as provisions
  - Embedding pollution from question numbers
  - Provisional matches not distinguished from confirmed
- ⬜ Fix extraction prompts based on Red Team findings
- ⬜ Re-extract corpus with improved prompts
- ⬜ Validate extraction quality (Red Team Sprint on extraction)
- ⬜ Re-generate crosswalks with clean data
- ⬜ Measure semantic mapping accuracy

### New Design Decisions (Oct 23, 2025):
| Date | Decision | Rationale | Impact |
|------|----------|-----------|--------|
| 2025-10-23 | Provisional matching model | BPD template matches depend on election compatibility - "the template is not the instance" | Three-level matching: template/election/instance |
| 2025-10-23 | AsyncIO for MVP | Better orchestration of parallel I/O-bound operations than ThreadPoolExecutor | 39 min → 20 min processing time |
| 2025-10-23 | Semantic fingerprinting | Strip section/question numbers before embedding to prevent pollution | Prevent false positives (e.g., Age Q 3.01 → State Q 3.01) |
| 2025-10-23 | Test corpus is Relius → Ascensus | Lauren Leneis confirmed vendor identity despite ASC branding in Relius docs | Cross-vendor validation (hardest use case) |
```

**Add to folder structure:**
```markdown
├── data_models/
│   ├── provision_model.md              # Provision structure & taxonomy
│   ├── mapping_model.md                # Source→Target mappings with confidence
│   ├── provisional_matching.md         # NEW: Template/election/instance matching model
│   ├── crosswalk_model.md              # Crosswalk output structure
│   └── variance_model.md               # Variance types (to be created)

├── performance_optimization.md         # NEW: AsyncIO strategy, parallelization, cost analysis
```

---

### `/design/architecture/system_architecture.md`

**Status**: ⏭️ **NOT REVIEWED** (assumed to need updates)

**Recommended Review:**
- Check if architecture diagram includes provisional match confirmation step
- Verify async/await orchestration is documented
- Ensure BPD + AA dual crosswalk workflow is shown

---

### `/design/data_models/provision_model.md`

**Status**: ⚠️ **NEEDS INTEGRATION WITH PROVISIONAL MATCHING**

**Current State:**
- Defines provision JSON schema
- Includes provision types (eligibility_rule, contribution_formula, etc.)
- Has extraction metadata fields

**Issues:**
1. **No manifestation field**: Doesn't distinguish BPD_TEMPLATE vs AA_ELECTION vs MERGED_INSTANCE
2. **No election dependencies**: Doesn't track which elections a BPD provision depends on
3. **No semantic fingerprint**: Doesn't document clean semantic text extraction

**Recommended Updates:**
- Add reference to `provisional_matching.md` for extended schema
- Note that base model is extended for different manifestations
- Add example of how provision_type enables smart candidate filtering

---

### `/design/data_models/mapping_model.md`

**Status**: ⚠️ **NEEDS INTEGRATION WITH PROVISIONAL MATCHING**

**Current State:**
- Defines source→target mapping structure
- Includes confidence scoring
- Has variance classification

**Issues:**
1. **No match_type field**: Doesn't distinguish TEMPLATE_MATCH vs ELECTION_MATCH vs INSTANCE_MATCH
2. **No validation_status**: Doesn't track PENDING vs CONFIRMED vs BLOCKED
3. **No is_provisional flag**: Doesn't indicate when election validation is required
4. **No dependencies object**: Doesn't track which elections must be validated for confirmation

**Recommended Updates:**
- Add reference to `provisional_matching.md` for extended schema
- Document confidence penalty model (-15% provisional, -40% blocked)
- Show example CSV output with provisional flag

---

### `/design/data_models/crosswalk_model.md`

**Status**: ⏭️ **NOT REVIEWED** (assumed OK but may need updates)

**Recommended Review:**
- Check if it documents dual BPD + AA crosswalk generation
- Verify it includes confirmation step (Step 3 in provisional_matching.md)

---

### `/design/data_models/provisional_matching.md`

**Status**: ✅ **NEW - COMPLETE** (created Oct 23, 2025)

**Contents:**
- Three-level matching model (template/election/instance)
- Provisional match definition and examples
- Unified provision schema with manifestations
- Semantic fingerprinting rules
- Match validation workflow
- Confidence scoring with provisional penalties
- CSV output format

**Integration Status:**
- Not yet referenced by other design docs
- Needs to be incorporated into README.md folder structure
- Should be primary reference for provision_model.md and mapping_model.md updates

---

### `/design/performance_optimization.md`

**Status**: ✅ **NEW - COMPLETE** (created Oct 23, 2025)

**Contents:**
- Current workflow performance (39 min baseline)
- Parallelization analysis (Steps 1+2 can run parallel)
- Tier 1/2/3 optimizations with time/cost savings
- AsyncIO vs ThreadPoolExecutor comparison
- Performance budget and roadmap (39 min → 20 min MVP target)
- Monitoring and cost analysis

**Integration Status:**
- Not yet referenced in README.md
- Should inform architecture updates (async/await strategy)

---

### `/design/llm_strategy/` Directory

**Status**: ✅ **COMPLETE** (documents exist, prompts externalized)

**Files:**
- `README.md` - Navigation guide
- `model_selection.md` - GPT-5 vision + GPT-4.1 semantic rationale
- `decision_matrix.md` - Quick reference scorecard
- `llm_research_report.md` - Comprehensive research findings

**Gap Identified:**
- ⚠️ **No `prompt_management.md`**: Prompts are externalized to `/prompts` directory, but design doesn't document HOW prompts integrate with architecture

**Recommended New Doc:** `/design/llm_strategy/prompt_management.md`

---

### Prompts vs Design: The Missing Link

**Current State:**
- `/prompts/README.md` documents prompt development workflow
- `/prompts/*.txt` contains actual prompts (version controlled)
- `/design/llm_strategy/` documents model selection but not prompt strategy

**Gap:**
- Design docs don't explain HOW prompts are loaded at runtime
- Design docs don't document WHICH prompts are used for WHICH operations
- No design-level discussion of prompt versioning strategy

**Recommended Solution:** Create `/design/llm_strategy/prompt_management.md`

---

## Prompt Management in Design (NEW DOC NEEDED)

### `/design/llm_strategy/prompt_management.md` (DRAFT OUTLINE)

**Should Document:**

1. **Prompt Architecture**
   - Where prompts live (`/prompts/*.txt`)
   - How code loads prompts at runtime
   - Versioning strategy (v1, v2, v3)
   - Approval workflow (draft → review → approve → deploy)

2. **Prompt Inventory**
   - `provision_extraction_v3.txt` - Vision extraction of BPD provisions
   - `aa_extraction_v3.txt` - Vision extraction of AA elections
   - `semantic_mapping_v1.txt` - BPD provision comparison
   - `aa_semantic_mapping_v1.txt` - AA election comparison
   - (Future) `instance_mapping_v1.txt` - Merged provision comparison

3. **Prompt Design Principles**
   - Structured output (JSON schema enforcement)
   - Domain accuracy (no hallucinated IRC refs)
   - Confidence calibration (abstention thresholds)
   - Cross-vendor compatibility

4. **Integration Points**
   - VisionExtractor class loads `provision_extraction_v3.txt`
   - SemanticMapper class loads `semantic_mapping_v1.txt`
   - Prompts parameterized with provision objects at runtime

5. **Testing Strategy**
   - Each prompt version tested before approval
   - Red Team Sprint validation on prompt outputs
   - Accuracy measurement (LLM output vs SME review)

6. **Prompt Evolution Based on Red Team Findings**
   - v1 → v2: Add chain-of-thought reasoning
   - v2 → v3: Add negative examples (Age ≠ State)
   - v3 → v4: Add section heading exclusion rules

**Cross-References:**
- Implements LLM strategy from `model_selection.md`
- Supports semantic matching defined in `provisional_matching.md`
- Enables semantic fingerprinting per `performance_optimization.md`

---

## Missing Design Documents

### High Priority (Should Exist)

1. **`/design/data_models/variance_model.md`**
   - Define Administrative / Design / Regulatory classification
   - Define High / Medium / Low impact levels
   - Provide classification decision tree
   - Show examples from market research (HCE safe harbor case)

2. **`/design/llm_strategy/prompt_management.md`** (outlined above)

3. **`/design/reconciliation/semantic_fingerprinting.md`**
   - Document what to include (legal concepts, regulatory refs)
   - Document what to exclude (section numbers, question numbers)
   - Provide implementation examples
   - Explain embedding pollution problem and solution

### Medium Priority (Can Wait)

4. **`/design/modules/extraction/vision_extraction.md`**
   - Document GPT-5-nano strategy
   - Explain fallback logic (if vision fails, try text API)
   - Show extraction prompt lifecycle

5. **`/design/testing_validation/red_team_sprint_methodology.md`**
   - Formalize Red Team Sprint process
   - Define sampling strategies
   - Document exit criteria
   - Show example findings report

### Low Priority (Post-MVP)

6. **`/design/modules/reconciliation/election_merging.md`**
   - Define BPD + AA → merged instance process
   - Document placeholder substitution logic
   - Handle conditional provisions

---

## Consistency Issues Identified

### Issue 1: Test Corpus Identity

**Problem**: Multiple docs reference "Ascensus Cycle 3" or "Ascensus intra-vendor" but actual corpus is Relius → Ascensus cross-vendor.

**Affected Files:**
- `/design/README.md` - Design decision log, Phase 2 status
- Possibly `/design/architecture/system_architecture.md` (not reviewed)
- Possibly module design docs (not yet created)

**Fix**: Update all references to:
- "Relius → Ascensus cross-vendor conversion"
- Note: Relius docs show ASC branding (prior plan history)
- Emphasize this tests hardest use case (cross-vendor)

---

### Issue 2: Confidence Scoring Model

**Problem**: Existing docs may define confidence thresholds (90/70) but don't account for provisional match penalties.

**Affected Files:**
- `/design/data_models/mapping_model.md` - May have old confidence scoring
- `/requirements/functional_requirements.md` - REQ-024 may need update

**Fix**: Confidence model should be:
```
Base LLM Confidence: 0.0 - 1.0
Provisional Penalty: -0.15 (if election validation pending)
Blocked Penalty: -0.40 (if elections incompatible)
Final Confidence: Base - Penalty

Thresholds:
- High: ≥0.90
- Medium: 0.70 - 0.89
- Low: <0.70 (abstain)
```

---

### Issue 3: Match Rate Interpretation

**Problem**: 19% BPD match rate may seem low but is actually correct for cross-vendor templates.

**Context Needed Everywhere:**
- BPD templates contain "as elected in AA" placeholders
- Many provisions are election-dependent (can't match definitively)
- Cross-vendor means different terminology, section numbering
- 19% represents semantic equivalence of core legal structure
- Remaining 81% are either vendor-specific or provisional matches

**Affected Files:**
- Design docs discussing accuracy targets
- Test validation docs discussing success criteria

**Fix**: Always contextualize match rates with:
1. What type of match (template vs election vs instance)
2. Cross-vendor vs intra-vendor scenario
3. Provisional vs confirmed distinction

---

## Integration Recommendations

### Update Sequence (Suggested Order)

1. **Update `/design/README.md`**
   - Add new design docs to folder structure
   - Update Phase 2 status with Red Team findings
   - Add Oct 23 design decisions
   - Update test corpus description

2. **Create `/design/llm_strategy/prompt_management.md`**
   - Document prompt architecture
   - Link prompts to operations
   - Explain runtime loading
   - Show approval workflow

3. **Create `/design/data_models/variance_model.md`**
   - Define classification system
   - Provide decision tree
   - Show examples

4. **Create `/design/reconciliation/semantic_fingerprinting.md`**
   - Document inclusion/exclusion rules
   - Show implementation
   - Explain embedding pollution fix

5. **Update `/design/data_models/provision_model.md`**
   - Add reference to provisional_matching.md
   - Note extended schema for manifestations
   - Update examples

6. **Update `/design/data_models/mapping_model.md`**
   - Add reference to provisional_matching.md
   - Document match_type, validation_status
   - Update confidence scoring with penalties

7. **Review and update `/design/architecture/system_architecture.md`**
   - Ensure provisional match workflow is shown
   - Add async/await orchestration
   - Show BPD + AA dual crosswalk

---

## Questions for Sergio

1. **Prompt management location**: Should prompt strategy live in `/design/llm_strategy/` or in `/prompts/`?
   - Current: `/prompts/README.md` has workflow, but it's implementation-focused
   - Recommendation: Design-level strategy in `/design`, implementation details in `/prompts`

2. **Variance model priority**: REQ-022 requires variance classification, but no design doc exists. Should we create this before revising extraction prompts?

3. **Architecture updates**: Should I review and update `system_architecture.md` now, or wait until extraction fixes are validated?

4. **Module design docs**: README.md lists `/design/modules/` structure but most modules aren't designed yet. Should we defer detailed module design until extraction quality is fixed?

5. **Testing validation docs**: Should we formalize Red Team Sprint methodology in design, or keep it as ad-hoc quality validation?

---

## Summary of Actions

### Immediate (Before Next Extraction Iteration)

- [ ] Update `/design/README.md` with current status and new docs
- [ ] Create `/design/llm_strategy/prompt_management.md`
- [ ] Create `/design/reconciliation/semantic_fingerprinting.md`
- [ ] Update test corpus references everywhere (Relius → Ascensus)

### Short-Term (After Extraction Fixes)

- [ ] Update `/design/data_models/provision_model.md` with manifestations
- [ ] Update `/design/data_models/mapping_model.md` with provisional matching
- [ ] Create `/design/data_models/variance_model.md`
- [ ] Review and update `/design/architecture/system_architecture.md`

### Medium-Term (MVP Preparation)

- [ ] Create module design docs for extraction, reconciliation, output
- [ ] Create testing/validation methodology docs
- [ ] Document deployment model (async/await, Docker, etc.)

---

## Audit Conclusion

**Design Directory Health**: 70% complete, on track for MVP

**Strengths:**
- ✅ Core conceptual models well-defined (provision, mapping, crosswalk)
- ✅ LLM strategy thoroughly researched and documented
- ✅ Prompt externalization working well
- ✅ New provisional matching model addresses critical gap

**Gaps:**
- ⚠️ Prompt management not documented in design
- ⚠️ Variance classification model missing
- ⚠️ Semantic fingerprinting not formalized in design
- ⚠️ Some inconsistencies in test corpus descriptions

**Risk Assessment:**
- **Low risk**: Core models are solid, gaps are documentation not conceptual
- **Medium risk**: Need to update existing docs for consistency before MVP
- **No blockers**: Can proceed with extraction fixes in parallel with doc updates

**Recommendation**: Prioritize immediate actions (README.md update, prompt management doc, semantic fingerprinting doc) before next extraction iteration. Defer module design until extraction quality is validated.

---

*Audit Conducted: 2025-10-23*
*Auditor: Claude (with Sergio DuBois)*
*Next Review: After extraction prompts revised and re-validated*
