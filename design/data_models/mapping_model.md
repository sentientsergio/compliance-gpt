# Mapping Data Model

## Overview

A **mapping** represents a semantic relationship between a source provision and a target provision. It is the core output of REQ-021 (Semantic Provision Mapping) and forms the basis for variance detection (REQ-022) and confidence scoring (REQ-024).

**Key Insight:** Mappings are not just links—they include the AI's reasoning, confidence score, and match quality metrics. This enables graduated human review (high confidence → bulk approve, low confidence → manual review).

---

## Requirements Addressed

- **REQ-021:** Semantic provision mapping with confidence scoring and reasoning
- **REQ-022:** Variance detection and classification (requires matched pairs)
- **REQ-024:** Confidence scoring and abstention (90/70/low thresholds)

---

## Design Principles

1. **Explainable:** Every mapping includes reasoning (why these provisions match)
2. **Auditable:** Preserve match alternatives (what else was considered?)
3. **Confidence-driven:** Graduated thresholds guide review workflow
4. **Handles missing provisions:** Map 1:0 (source→nothing) and 0:1 (nothing→target)
5. **Human-correctable:** Support user overrides and feedback

---

## JSON Schema

```json
{
  "mapping_id": "string (UUID)",
  "source_provision_id": "string | null (UUID, null if new target provision)",
  "target_provision_id": "string | null (UUID, null if missing in target)",
  "mapping_type": "enum ['exact_match', 'semantic_match', 'partial_match', 'missing_in_target', 'new_in_target', 'no_match']",
  "confidence_score": "float [0.0-1.0]",
  "confidence_level": "enum ['high', 'medium', 'low'] (derived from score)",
  "match_reasoning": "string (LLM explanation of why these provisions match)",
  "match_evidence": {
    "extracted_entities_match": "boolean (do ages, percentages, etc. align?)",
    "keyword_overlap": "float [0.0-1.0] (Jaccard similarity of keywords)",
    "semantic_similarity": "float [0.0-1.0] (embedding cosine similarity or LLM score)",
    "section_proximity": "float [0.0-1.0] (are sections in similar document positions?)"
  },
  "alternative_matches": [
    {
      "target_provision_id": "string (UUID)",
      "confidence_score": "float",
      "reasoning": "string (why this was considered but not selected)"
    }
  ],
  "variance_detected": "boolean (does mapped pair have textual differences?)",
  "variance_summary": "string | null (brief description of difference, e.g., 'Age requirement changed from 21 to 18')",
  "user_review": {
    "status": "enum ['pending', 'approved', 'rejected', 'overridden']",
    "reviewed_by": "string | null (user ID or email)",
    "reviewed_at": "string | null (ISO 8601 timestamp)",
    "override_target_id": "string | null (if user manually corrected mapping)",
    "notes": "string | null (user comments)"
  },
  "created_at": "string (ISO 8601 timestamp)",
  "updated_at": "string (ISO 8601 timestamp)"
}
```

---

## Mapping Types (Taxonomy)

| Type | Description | Confidence Typical | Example |
|------|-------------|-------------------|---------|
| `exact_match` | Text nearly identical (minor wording differences only) | High (0.95-1.0) | Source: "Age 21 and 1 year" → Target: "Age 21 and 12 months" |
| `semantic_match` | Different wording but same meaning | Medium-High (0.75-0.95) | Source: "Forfeitures reduce contributions" → Target: "Apply forfeitures to future obligations" |
| `partial_match` | Provisions overlap but not fully equivalent | Medium-Low (0.50-0.75) | Source: "Age 21 OR 1 year" → Target: "Age 21 AND 1 year" (logic changed) |
| `missing_in_target` | Source provision has no equivalent in target | N/A (flagged HIGH priority) | Source: "HCEs included in safe harbor" → Target: (provision absent) |
| `new_in_target` | Target provision has no source equivalent | N/A (flagged MEDIUM priority) | Source: (provision absent) → Target: "Roth 401(k) deferrals allowed" |
| `no_match` | Low confidence, AI abstains from mapping | Low (<0.50) | Ambiguous section, requires manual review |

---

## Field Definitions

### Core Fields

**`mapping_id`** (string, UUID)
- Unique identifier for this mapping
- Used for audit trail and user review tracking

**`source_provision_id`** (string | null, UUID)
- References provision in source document
- **Null** if `mapping_type` is `new_in_target` (no source equivalent)

**`target_provision_id`** (string | null, UUID)
- References provision in target document
- **Null** if `mapping_type` is `missing_in_target` (no target equivalent)

**`mapping_type`** (enum)
- Classification of match quality (see taxonomy above)
- Drives UI display (exact matches shown as green, partial as yellow, missing as red)

**`confidence_score`** (float, 0.0-1.0)
- Numeric confidence in this mapping
- Generated by LLM (via self-evaluation, log probabilities, or embedding similarity)
- Used to compute `confidence_level`

**`confidence_level`** (enum: `high` | `medium` | `low`)
- Derived from `confidence_score` using thresholds (REQ-024):
  - **High:** 0.90-1.0 (suggest bulk approval)
  - **Medium:** 0.70-0.89 (require individual review)
  - **Low:** 0.0-0.69 (flag for manual review, abstain from auto-classification)
- Determines review workflow in UI

**`match_reasoning`** (string)
- LLM-generated explanation of why these provisions map
- Examples:
  - High confidence: "Both provisions specify identical eligibility requirements: age 21 and completion of 1 year of service (1,000 hours)."
  - Medium confidence: "Source requires 'age 21 OR 1 year' while target requires 'age 21 AND 1 year'. This is a substantive design change."
  - Low confidence: "Source mentions 'vesting schedule' in Section 4.03 but no clear equivalent found in target document. Manual review required."
- Displayed in UI to help user validate mapping

---

### Match Evidence Object

Provides quantitative metrics supporting the confidence score. Useful for:
- Debugging why AI made certain mappings
- Calibrating confidence thresholds
- Transparent AI (show user the factors)

**`extracted_entities_match`** (boolean)
- Do structured entities (ages, percentages, dates) align?
- Example: Both have `ages: [21]` and `service_years: [1.0]` → `true`
- Strong signal for high confidence (if entities match, provisions likely equivalent)

**`keyword_overlap`** (float, 0.0-1.0)
- Jaccard similarity of extracted keywords
- Example: Source keywords `["eligibility", "age", "service"]` vs Target `["participant", "age", "employment"]` → 0.33 (1 of 3 shared)
- Useful for fast filtering (low keyword overlap → likely not a match)

**`semantic_similarity`** (float, 0.0-1.0)
- Cosine similarity of provision text embeddings (if using embedding-based approach)
- OR: LLM-assigned similarity score (if using prompt-based approach)
- High values (>0.85) suggest semantic equivalence

**`section_proximity`** (float, 0.0-1.0)
- Are provisions in similar positions in their documents?
- Example: Source provision is 10% into document, target is 12% → high proximity (0.98)
- Weak signal but useful tie-breaker (documents usually follow similar structure)

---

### Alternative Matches Array

**Design Decision:** Alternative matches are **NOT stored** in the mapping model.

**Rationale:**
- Confidence scoring should identify the single best match
- If multiple candidates have similarly weak confidence (no clear winner), the system should **abstain** and flag for manual review
- Storing alternatives adds complexity without clear value for the review workflow
- In CLI interface, users can't easily navigate alternatives anyway

**Abstention Logic:**
```python
if best_match_confidence >= 0.70 and (best_match_confidence - second_best_confidence) >= 0.15:
    # Clear winner with sufficient margin
    create_mapping(best_match, confidence)
else:
    # No clear winner or too low confidence
    create_mapping(source_id, target_id=null, type="no_match", confidence=best_match_confidence)
    flag_for_manual_review()
```

**Field remains in schema (empty array) for future extensibility:**
```json
"alternative_matches": []
```

---

### Variance Fields

**`variance_detected`** (boolean)
- Do the mapped provisions have textual differences?
- `exact_match` → usually `false`
- `semantic_match` → usually `true` (same meaning, different wording)
- Used to trigger variance analysis (REQ-022)

**`variance_summary`** (string | null)
- Brief description of the difference
- Examples:
  - "Age requirement changed from 21 to 18"
  - "Wording updated but substantively identical (administrative change)"
  - "Contribution formula revised: was 3% match, now 4% match"
- Populated by variance detection module (separate from mapping)
- Null if `variance_detected` is `false`

---

### User Review Object

Tracks human validation and overrides (REQ-051 human-in-loop)

**`status`** (enum)
- `pending`: Awaiting user review (default state)
- `approved`: User confirmed mapping is correct
- `rejected`: User rejected mapping (will re-map manually or flag as error)
- `overridden`: User manually corrected the target provision

**`reviewed_by`** (string | null)
- User ID or email of reviewer
- Used for audit trail (REQ-043)
- Supports multiple reviewers in sequence (CLI workflow: one reviewer at a time, not concurrent)

**`reviewed_at`** (string | null, ISO 8601)
- Timestamp of review action
- Used for audit trail

**`override_target_id`** (string | null, UUID)
- If user manually selected a different target provision, store it here
- Allows learning from corrections (post-MVP: improve model with user feedback)

**`notes`** (string | null)
- Free-text comments from user
- Examples:
  - "Confirmed with legal counsel - these are equivalent despite wording difference"
  - "Flagged for sponsor approval - contribution rate changed"
  - "AI missed this - target provision is actually in Amendment 2023-05, not main BPD"

---

### Timestamps

**`created_at`** (string, ISO 8601)
- When this mapping was created by AI

**`updated_at`** (string, ISO 8601)
- Last modification (e.g., user override, confidence recalculation)

---

## Example: High-Confidence Exact Match

```json
{
  "mapping_id": "map-001",
  "source_provision_id": "550e8400-e29b-41d4-a716-446655440000",
  "target_provision_id": "661e9511-f30c-52e5-b827-557766551111",
  "mapping_type": "exact_match",
  "confidence_score": 0.97,
  "confidence_level": "high",
  "match_reasoning": "Both provisions specify identical eligibility requirements: age 21 and completion of 1 year of service (1,000 hours in 12 months). Only difference is stylistic: source uses 'Employee' while target uses 'Participant'.",
  "match_evidence": {
    "extracted_entities_match": true,
    "keyword_overlap": 0.85,
    "semantic_similarity": 0.96,
    "section_proximity": 0.92
  },
  "alternative_matches": [],
  "variance_detected": false,
  "variance_summary": null,
  "user_review": {
    "status": "approved",
    "reviewed_by": "analyst@tpa.com",
    "reviewed_at": "2025-10-17T15:30:00Z",
    "override_target_id": null,
    "notes": "Confirmed - administrative wording change only"
  },
  "created_at": "2025-10-17T14:50:00Z",
  "updated_at": "2025-10-17T15:30:00Z"
}
```

---

## Example: Medium-Confidence Semantic Match with Variance

```json
{
  "mapping_id": "map-042",
  "source_provision_id": "src-042",
  "target_provision_id": "tgt-038",
  "mapping_type": "semantic_match",
  "confidence_score": 0.82,
  "confidence_level": "medium",
  "match_reasoning": "Both provisions address forfeiture allocation. Source states 'forfeitures will be used to reduce employer contributions' while target states 'the Plan Administrator may apply forfeitures to reduce future contribution obligations'. Semantically equivalent but target adds discretionary language ('may apply' vs. 'will be used').",
  "match_evidence": {
    "extracted_entities_match": false,
    "keyword_overlap": 0.72,
    "semantic_similarity": 0.84,
    "section_proximity": 0.68
  },
  "alternative_matches": [],
  "variance_detected": true,
  "variance_summary": "Forfeiture usage changed from mandatory ('will be used') to discretionary ('may apply'). This is a substantive design change requiring sponsor approval.",
  "user_review": {
    "status": "pending",
    "reviewed_by": null,
    "reviewed_at": null,
    "override_target_id": null,
    "notes": null
  },
  "created_at": "2025-10-17T14:52:15Z",
  "updated_at": "2025-10-17T14:52:15Z"
}
```

---

## Example: Missing in Target (High Priority)

```json
{
  "mapping_id": "map-087",
  "source_provision_id": "src-087",
  "target_provision_id": null,
  "mapping_type": "missing_in_target",
  "confidence_score": null,
  "confidence_level": null,
  "match_reasoning": "Source provision 'Highly Compensated Employees are included in safe harbor contributions' has no equivalent in target document. This is a critical omission - ASC documents require explicit election for HCE inclusion, but checkbox was not marked in Adoption Agreement.",
  "match_evidence": {
    "extracted_entities_match": false,
    "keyword_overlap": 0.0,
    "semantic_similarity": 0.0,
    "section_proximity": 0.0
  },
  "alternative_matches": [],
  "variance_detected": true,
  "variance_summary": "CRITICAL: HCE inclusion in safe harbor contributions is missing in target. Relius auto-includes HCEs by default; ASC requires explicit checkbox selection.",
  "user_review": {
    "status": "pending",
    "reviewed_by": null,
    "reviewed_at": null,
    "override_target_id": null,
    "notes": null
  },
  "created_at": "2025-10-17T14:55:33Z",
  "updated_at": "2025-10-17T14:55:33Z"
}
```

**Note:** This example directly addresses the pain point from market research (p.3): "Relius had automatically allowed a discretionary safe harbor contribution to include Highly Compensated Employees by default, whereas the new ASC document required checking a box to include HCEs, which the preparer missed."

---

## Example: New in Target (Medium Priority)

```json
{
  "mapping_id": "map-104",
  "source_provision_id": null,
  "target_provision_id": "tgt-104",
  "mapping_type": "new_in_target",
  "confidence_score": null,
  "confidence_level": null,
  "match_reasoning": "Target provision 'Participants may make Roth 401(k) deferrals' has no equivalent in source document. This is a new plan feature added in the restated document.",
  "match_evidence": {
    "extracted_entities_match": false,
    "keyword_overlap": 0.0,
    "semantic_similarity": 0.0,
    "section_proximity": 0.0
  },
  "alternative_matches": [],
  "variance_detected": true,
  "variance_summary": "NEW FEATURE: Roth 401(k) deferrals added. Requires sponsor confirmation and participant communication.",
  "user_review": {
    "status": "pending",
    "reviewed_by": null,
    "reviewed_at": null,
    "override_target_id": null,
    "notes": null
  },
  "created_at": "2025-10-17T14:58:10Z",
  "updated_at": "2025-10-17T14:58:10Z"
}
```

---

## Example: Low Confidence / No Match (Requires Manual Review)

```json
{
  "mapping_id": "map-063",
  "source_provision_id": "src-063",
  "target_provision_id": null,
  "mapping_type": "no_match",
  "confidence_score": 0.42,
  "confidence_level": "low",
  "match_reasoning": "Source provision references 'special vesting schedule for participants employed on the Effective Date' but no clear equivalent found in target. Possible matches in target Sections 5.02 and 5.04 but both scored below confidence threshold. Manual review required to determine if provision was moved, merged, or removed.",
  "match_evidence": {
    "extracted_entities_match": false,
    "keyword_overlap": 0.35,
    "semantic_similarity": 0.48,
    "section_proximity": 0.52
  },
  "alternative_matches": [
    {
      "target_provision_id": "tgt-052",
      "confidence_score": 0.42,
      "reasoning": "Discusses vesting but for new participants, not existing employees"
    },
    {
      "target_provision_id": "tgt-054",
      "confidence_score": 0.38,
      "reasoning": "Mentions 'Effective Date' but in context of plan mergers, not vesting"
    }
  ],
  "variance_detected": false,
  "variance_summary": null,
  "user_review": {
    "status": "pending",
    "reviewed_by": null,
    "reviewed_at": null,
    "override_target_id": null,
    "notes": null
  },
  "created_at": "2025-10-17T14:53:42Z",
  "updated_at": "2025-10-17T14:53:42Z"
}
```

---

## Confidence Scoring Strategy (To Be Validated in Phase 2 POC)

**Question:** How do we generate reliable 0-100% confidence scores?

**Option A: LLM Self-Evaluation**
- Prompt: "Rate your confidence in this mapping from 0-100%"
- Pros: Simple, no additional infrastructure
- Cons: May not calibrate well (LLMs tend to be overconfident)

**Option B: Embedding Similarity**
- Compute text embeddings for source and target provisions
- Cosine similarity → confidence score
- Pros: Objective, repeatable
- Cons: May miss semantic nuance (different wording, same meaning → low score)

**Option C: Hybrid Score**
- Combine multiple signals:
  - `0.4 * semantic_similarity` (embedding)
  - `0.3 * extracted_entities_match` (1.0 if match, 0.0 if not)
  - `0.2 * keyword_overlap`
  - `0.1 * section_proximity`
- Pros: Robust, explainable
- Cons: Requires tuning weights

**Option D: LLM with Structured Reasoning**
- Prompt LLM to output structured JSON:
  ```json
  {
    "match_quality": "high | medium | low",
    "confidence_score": 0.85,
    "reasoning": "Both specify age 21...",
    "factors": {
      "entities_match": true,
      "semantic_similarity": "high",
      "concerns": []
    }
  }
  ```
- Pros: Combines LLM understanding with structured scoring
- Cons: Relies on prompt engineering quality

**Recommendation for POC:** Try Option D (structured LLM reasoning). If calibration is poor, fall back to Option C (hybrid score).

---

## Mapping Workflow

```
1. Extract Provisions
   → Source provisions: [p1, p2, ..., pN]
   → Target provisions: [q1, q2, ..., qM]

2. For Each Source Provision pi:
   a. Compare pi to ALL target provisions [q1...qM] (via embedding filter + LLM)
   b. Score each pair (pi, qj) → confidence_score
   c. Identify best match and second-best match
   d. Decision logic:
      - If best_confidence ≥ 0.70 AND (best - second_best) ≥ 0.15:
          → Create mapping with best match (clear winner)
      - If best_confidence ≥ 0.70 BUT (best - second_best) < 0.15:
          → Abstain (ambiguous, no clear winner) → flag "no_match"
      - If best_confidence < 0.70:
          → Flag as "no_match" or "missing_in_target"

3. For Each Target Provision qj:
   a. Check if qj was matched by any source provision
   b. If NOT matched → create mapping_type: "new_in_target"

4. Sort Mappings by Confidence:
   - Low confidence first (requires manual review)
   - High confidence last (bulk approval candidate)

5. Present to User (CLI):
   - Display low-confidence mappings for individual review
   - Offer bulk approval for high-confidence mappings (>90%)
   - Sequential review (one reviewer at a time, save state between sessions)
```

---

## Design Decisions

### Decision 1: Null Provision IDs for Missing/New
**Context:** How to represent missing provisions (1:0) or new provisions (0:1)?

**Selected:** Use `null` for missing provision ID + explicit `mapping_type`

**Rationale:**
- Preserves referential integrity (non-null IDs always reference valid provisions)
- `mapping_type` makes intent explicit (missing vs. new vs. no_match)
- Easier to query ("show me all missing provisions" → filter by `target_provision_id == null`)

---

### Decision 2: Alternative Matches - Not Stored
**Context:** Should we preserve runner-up matches, or only the top match?

**Selected:** Do NOT store alternative matches (array remains empty)

**Rationale:**
- **Confidence should pick a clear winner:** If confidence is high enough (≥70%) AND there's a clear gap from second-best (≥15% margin), create the mapping
- **Abstain when ambiguous:** If multiple candidates have similar confidence (close race), system should abstain and flag for manual review
- **CLI workflow limitation:** Users can't easily navigate alternatives in command-line interface
- **Reduces complexity:** Simpler data model, fewer objects to display/manage
- **Separation of concerns:** Semantic mapping should propose ONE answer or abstain, not present multiple options

---

### Decision 3: Variance Summary in Mapping vs. Separate Object
**Context:** Should variance details live in mapping object or separate variance object?

**Selected:** Store basic variance flag + summary in mapping, full variance analysis in separate `variance_model.md` (Control 002)

**Rationale:**
- Mapping should answer: "Do these provisions match?"
- Variance should answer: "How do they differ and what does it mean?"
- Separation of concerns: Mapping module outputs mappings, variance detection module outputs variances
- Both reference the same mapping_id for linkage

---

## Open Questions

1. **Should we support many-to-one mappings?** (Multiple source provisions → single target provision if target merged concepts)
2. **How to handle provision splits?** (Single source → multiple target provisions if target split concepts)
3. **Confidence recalibration:** Should confidence scores update based on user feedback? (Post-MVP learning)
4. **Multi-reviewer workflow:** How to handle handoff between reviewers in CLI? (Save state, mark "in progress", prevent conflicts)

---

## Testing Strategy

**Unit Tests:**
- Validate mapping JSON schema
- Test confidence_level derivation (0.95 → "high", 0.75 → "medium", etc.)
- Verify null handling (missing/new provisions)

**Integration Tests:**
- Map 10 source provisions → 10 target provisions (same document, should be 10 exact matches)
- Map Relius provisions → ASC provisions (cross-vendor, expect semantic matches)
- Detect missing provisions (remove 1 target provision → should flag as missing_in_target)

**User Testing:**
- Present mappings to compliance expert → measure agreement rate
- Target: ≥70% of high-confidence mappings accepted without modification
- Track: % of low-confidence mappings that user can resolve (vs. truly ambiguous)

---

## References

- **Requirements:** [REQ-021 (Semantic Mapping)](../../requirements/functional_requirements.md#req-021-semantic-provision-mapping-critical---core-differentiator)
- **Requirements:** [REQ-024 (Confidence Scoring)](../../requirements/functional_requirements.md#req-024-confidence-scoring-and-abstention)
- **Provision Model:** [provision_model.md](./provision_model.md)
- **Variance Model:** [variance_model.md](./variance_model.md) (to be created)
- **System Architecture:** [/design/architecture/system_architecture.md](../architecture/system_architecture.md)

---

*Last Updated: 2025-10-17*
*Status: Phase 1 Draft - Ready for POC*
